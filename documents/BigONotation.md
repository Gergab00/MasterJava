## Big O Notation

La notaci√≥n Big O es una forma de describir la complejidad temporal o espacial de un algoritmo o programa inform√°tico. La notaci√≥n Big O se utiliza para analizar el peor caso del rendimiento de un algoritmo, lo que significa que la complejidad se mide en t√©rminos de la cantidad de operaciones que un algoritmo realiza en funci√≥n del tama√±o de la entrada. La notaci√≥n Big O se utiliza para describir cu√°nto tiempo un algoritmo tardar√° en completarse en el peor de los casos.

Por ejemplo, si un algoritmo realiza una cantidad constante de operaciones para cualquier tama√±o de entrada, se dice que tiene una complejidad temporal O(1). Si un algoritmo realiza un n√∫mero de operaciones que es proporcional al tama√±o de la entrada, se dice que tiene una complejidad temporal O(n). Y si un algoritmo realiza un n√∫mero de operaciones que es proporcional al tama√±o de la entrada al cuadrado, se dice que tiene una complejidad temporal O(n^2).

> ‚ö†Ô∏è Es **importante** destacar que la notaci√≥n Big O se utiliza para describir un l√≠mite superior de la complejidad de un algoritmo, no su tiempo real de ejecuci√≥n. Adem√°s, se utiliza para comparar diferentes algoritmos y elegir el m√°s adecuado para una tarea espec√≠fica en funci√≥n de sus requisitos de tiempo y espacio.

Algunos ejemplos de notaciones comunes de Big O incluyen:

- **O(1)**, que significa que el tiempo de ejecuci√≥n es constante y no depende del tama√±o de la entrada.
    Aqu√≠ hay un ejemplo de c√≥digo Java que ilustra esto:
    
    ```java
    public static int getFirstElement(int[] array) {
        return array[0];
    }
    ```
    En este ejemplo, el m√©todo **`getFirstElement`** devuelve el primer elemento en el **`array`**. El m√©todo realiza una operaci√≥n constante, por lo que su complejidad temporal es **O(1)**.

    Esto significa que el tiempo de ejecuci√≥n del algoritmo no aumentar√° proporcionalmente a medida que el tama√±o de la entrada aumente.

    > üîë La clave para determinar si un algoritmo es O(1) es identificar las operaciones que tienen un tiempo constante de ejecuci√≥n. En este caso, la operaci√≥n consiste en acceder al primer elemento de un array, lo que siempre se realiza en un tiempo constante.

- **O(n)**, que significa que el tiempo de ejecuci√≥n es proporcional al tama√±o de la entrada. Por ejemplo, si un algoritmo toma 1 segundo para procesar 100 elementos, se esperar√≠a que tome 2 segundos para procesar 200 elementos.

    Un ejemplo de un algoritmo con complejidad **O(n)** es un algoritmo que realiza una operaci√≥n por cada elemento en una lista. Por ejemplo, podemos escribir un m√©todo que sume todos los elementos en una lista como sigue:

    ```java
    public static int sum(List<Integer> list) {
        int sum = 0;
        for (int i = 0; i < list.size(); i++) {
            sum += list.get(i);
        }
        return sum;
    }
    ```
    En este ejemplo, la complejidad temporal del m√©todo es **O(n)**, ya que el tiempo que tarda en ejecutarse es directamente proporcional al tama√±o de la lista. <ins>_Para cada elemento en la lista, el m√©todo realiza una operaci√≥n de adici√≥n, por lo que el tiempo total de ejecuci√≥n depende directamente del tama√±o de la lista_</ins>.

- **O(n^2)**, que significa que el tiempo de ejecuci√≥n es proporcional al cuadrado del tama√±o de la entrada. Por ejemplo, si un algoritmo toma 1 segundo para procesar 100 elementos, se esperar√≠a que tome 4 segundos para procesar 200 elementos.

    Aqu√≠ hay un ejemplo de un algoritmo que tiene una complejidad de **O(n^2)**:

    ```java
    public static void printPairs(int[] array) {
        for (int i = 0; i < array.length; i++) {
            for (int j = 0; j < array.length; j++) {
                System.out.println(array[i] + ", " + array[j]);
            }
        }
    }
    ```
    En este ejemplo, tenemos dos ciclos for anidados. El primer ciclo for itera a trav√©s de todos los elementos en el **`array`**, y el segundo ciclo for itera a trav√©s de los elementos restantes despu√©s del primer elemento. Por lo tanto, en total, estamos iterando a trav√©s de **`array.length * (array.length - 1) / 2`** pares, lo que es equivalente a **`n^2 / 2`** pares, donde **`n`** es el tama√±o de **`array`**. Por lo tanto, la complejidad de este algoritmo es **O(n^2)**.

- **O(log n)**, que significa que el tiempo de ejecuci√≥n aumenta logar√≠tmicamente con el tama√±o de la entrada. Por ejemplo, si un algoritmo toma 1 segundo para procesar 1,000 elementos, se esperar√≠a que tome aproximadamente 2 segundos para procesar 10,000 elementos.

    Aqu√≠ hay un ejemplo de c√≥digo Java que representa una operaci√≥n de complejidad **O(log n)**:
    
    ```java
    public static int binarySearch(int[] array, int target) {
        int low = 0;
        int high = array.length - 1;
        while (low <= high) {
            int mid = (low + high) / 2;
            int guess = array[mid];
            if (guess == target) {
                return mid;
            }
            if (guess > target) {
                high = mid - 1;
            } else {
                low = mid + 1;
            }
        }
        return -1;
    }
    ```

    Este c√≥digo implementa una b√∫squeda binaria, un algoritmo que permite buscar un elemento en una secuencia ordenada de datos. La complejidad del algoritmo es **O(log n)** porque, en cada iteraci√≥n, la cantidad de elementos que deben ser revisados se divide a la mitad.

    Por lo tanto, a medida que el tama√±o de la secuencia aumenta, la cantidad de iteraciones necesarias para encontrar el elemento target se mantiene constante. En el peor de los casos, se necesitan log2(n) iteraciones para encontrar el elemento.

    > üí° **NOTA:** Cuando en una entrevista te preguntan sobre la complejidad de un algoritmo, es importante que menciones en una expresion **`Big O`** como el tama√±o del conjunto de datos afecta el rendimiento de ese algoritmo.

    